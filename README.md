# Latent Space Retrieval for Enhanced RAG in Computational Neuroscience

## Project Overview

This repository contains the code for a computational neuroscience research project exploring a novel approach to Retrieval-Augmented Generation (RAG). The core idea is to improve the retrieval of relevant context by searching in a learned latent space rather than directly in the text embedding space. This addresses the challenge where semantically similar information might not be textually similar, hindering traditional embedding distance-based retrieval methods.

This project focuses on applying this technique to computational neuroscience literature, aiming to enhance the ability of Large Language Models (LLMs) to answer questions based on conceptually similar information.

**Key Idea:**

Instead of relying on textual similarity between the query and the document chunks, we train a Sparse Autoencoder on the embeddings generated by a pre-trained LLM. This autoencoder learns a lower-dimensional latent space that captures more abstract, conceptual relationships within the data. Retrieval is then performed by finding the nearest neighbors in this latent space.

**Project Goals:**

*   Develop a RAG system that leverages a sparse autoencoder-derived latent space for context retrieval.
*   Evaluate the performance of this system compared to traditional embedding-based RAG in the context of computational neuroscience.
*   Demonstrate the ability of the latent space approach to retrieve conceptually similar but textually dissimilar information.

## Key Features

*   **LLM Embedding Generation:** Utilizes pre-trained Large Language Models (e.g., Sentence-BERT) to generate dense vector embeddings of the computational neuroscience text corpus.
*   **Sparse Autoencoder Training:** Implements a sparse autoencoder using PyTorch to learn a compressed, concept-rich latent representation of the LLM embeddings.
*   **Latent Space Indexing:** Employs FAISS (Facebook AI Similarity Search) for efficient nearest neighbor search within the learned latent space.
*   **Context Retrieval based on Latent Similarity:** Retrieves relevant context chunks by finding the closest latent representations to the query's latent representation.
*   **LLM Response Generation:** Uses a pre-trained LLM to generate answers based on the retrieved context and the user's question.
*   **Modular Design:** The codebase is designed with modular components for easy experimentation and extension.

## Getting Started

### Prerequisites

*   Python 3.8+
*   PyTorch
*   Hugging Face Transformers
*   Faiss (installation instructions might vary depending on your system, refer to the official Faiss repository)
*   NumPy
*   Scikit-learn
*   Pandas
*   A CUDA-enabled GPU is highly recommended for faster training and inference.

### Installation

1. **Clone the repository:**
    ```bash
    git clone https://github.com/yiheinchai/latentRAG.git
    cd latentRAG
    ```

2. **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate  # On Windows
    ```

3. **Install the required packages:**
    ```bash
    pip install -r requirements.txt
    ```

### Project Structure
latentRAG/
├── data/ # Directory for storing the dataset
├── models/ # Contains the model definitions (sparse autoencoder)
│ └── sparse_ae.py
├── retrieval/ # Logic for latent space retrieval
│ └── latent_retriever.py
├── embedding/ # Code for generating LLM embeddings
│ └── embedding_generator.py
├── response_generation/ # Code for generating responses with LLMs
│ └── response_generator.py
├── training/ # Scripts for training the sparse autoencoder
│ └── train_ae.py
├── evaluation/ # Scripts for evaluating the RAG system
│ └── evaluate_rag.py
├── notebooks/ # Jupyter notebooks for experimentation and analysis
├── requirements.txt # List of required Python packages
├── README.md # This file


## Usage

Here's a basic example of how to use the system:

1. **Prepare your data:** Place your computational neuroscience text data in the `data/` directory. You'll need to preprocess it into chunks suitable for embedding.

2. **Generate LLM embeddings:**
    ```bash
    python embedding/embedding_generator.py --data_path data/your_data.txt --output_path data/embeddings.pt
    ```

3. **Train the sparse autoencoder:**
    ```bash
    python training/train_ae.py --embeddings_path data/embeddings.pt --output_path models/sparse_ae.pth
    ```

4. **Run the latent space retrieval and response generation (example in a notebook or script):**

    ```python
    import torch
    from embedding.embedding_generator import EmbeddingGenerator
    from models.sparse_ae import SparseAutoencoder
    from retrieval.latent_retriever import LatentSpaceRetriever
    from response_generation.response_generator import LLMResponseGenerator

    # Load pre-trained models and data
    embedding_generator = EmbeddingGenerator() # Uses default Sentence-BERT model
    embeddings = torch.load("data/embeddings.pt")
    sparse_ae_model = SparseAutoencoder(input_dim=embeddings.shape[1], encoding_dim=128) # Adjust encoding_dim
    sparse_ae_model.load_state_dict(torch.load("models/sparse_ae.pth"))
    text_chunks = [...] # Load your preprocessed text chunks

    # Initialize the latent space retriever
    latent_retriever = LatentSpaceRetriever(sparse_autoencoder=sparse_ae_model,
                                             embedding_generator=embedding_generator,
                                             text_chunks=text_chunks)

    # Initialize the response generator
    response_generator = LLMResponseGenerator() # Uses default GPT-2 model

    # Ask a question
    query = "What is the role of NMDA receptors in synaptic plasticity?"
    retrieved_contexts = latent_retriever.retrieve_context(query)
    print("Retrieved Contexts:", retrieved_contexts)

    # Generate a response
    response = response_generator.generate_response(query, "\n".join(retrieved_contexts))
    print("Generated Response:", response)
    ```

**Note:**  You will need to adapt the data loading and preprocessing steps to your specific dataset format.

## Models

The `models/` directory contains the definition for the Sparse Autoencoder:

*   **`sparse_ae.py`:** Defines the `SparseAutoencoder` class, including the encoder and decoder architectures, and potentially sparsity-related loss functions.

## Retrieval

The `retrieval/` directory contains the logic for performing retrieval in the latent space:

*   **`latent_retriever.py`:** Implements the `LatentSpaceRetriever` class, which handles encoding text chunks and queries into the latent space and performing similarity search using FAISS.

## Embedding

The `embedding/` directory handles the generation of LLM embeddings:

*   **`embedding_generator.py`:** Contains the `EmbeddingGenerator` class responsible for loading a pre-trained LLM and generating embeddings for the text data.

## Response Generation

The `response_generation/` directory handles generating responses using an LLM:

*   **`response_generator.py`:** Implements the `LLMResponseGenerator` class, which takes a question and retrieved context, constructs a prompt, and generates a response using a pre-trained LLM.

## Training

The `training/` directory contains scripts for training the Sparse Autoencoder:

*   **`train_ae.py`:**  A script to train the `SparseAutoencoder` on the generated LLM embeddings, including setting up the optimizer, loss function, and training loop.

## Evaluation

The `evaluation/` directory will contain scripts for evaluating the performance of the RAG system:

*   **`evaluate_rag.py`:**  Scripts to compare the performance of the latent space RAG with a traditional embedding-based RAG, using metrics like relevance, answer accuracy, and potentially measures of conceptual similarity.

## Contributing

Contributions to this project are welcome! Please feel free to open issues for bug reports or feature requests, and submit pull requests for proposed changes.

## License

This project is licensed under the [MIT License](LICENSE).
